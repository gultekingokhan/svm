{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n",
      "[LibSVM]('training time: ', 0.097, 's', 0.0016166666666666666, 'mins')\n",
      "('Prediction time: ', 0.823, 's', 0.013716666666666665, 'mins')\n",
      "('Accuracy: ', 0.8924914675767918)\n",
      "('PREDICTIONS: ', 1, 0, 1)\n",
      "('i = ', 1018)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' When kernel set to rbf and optimizing C with the following values:\\n\\nC = 10          Acc = 0.6160409556313993\\nC = 100         Acc = 0.6160409556313993\\nC = 1000        Acc = 0.8213879408418657\\nC = 10000       Acc = 0.8924914675767918\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "\"\"\" \n",
    "    This is the code to accompany the Lesson 2 (SVM) mini-project.\n",
    "\n",
    "    Use a SVM to identify emails from the Enron corpus by their authors:    \n",
    "    Sara has label 0\n",
    "    Chris has label 1\n",
    "\"\"\"\n",
    "    \n",
    "import sys\n",
    "from time import time\n",
    "sys.path.append(\"../tools/\")\n",
    "from email_preprocess import preprocess\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "\n",
    "features_train = features_train[:len(features_train)/100] # To decrease the size of the training set.\n",
    "labels_train = labels_train[:len(labels_train)/100]\n",
    "#########################################################\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(C=10000.0, kernel='rbf', gamma='auto', verbose=True)\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "print (\"training time: \", round(time()-t0, 3), \"s\", (round(time()-t0, 3) / 60), \"mins\")\n",
    "\n",
    "t1 = time()\n",
    "\n",
    "predictedLabels = clf.predict(features_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print (\"Prediction time: \", round(time()-t1, 3), \"s\",  (round(time()-t1, 3) / 60), \"mins\")\n",
    "\n",
    "accuracyScore = accuracy_score(labels_test, predictedLabels)\n",
    "\n",
    "print(\"Accuracy: \", accuracyScore)\n",
    "\n",
    "print(\"PREDICTIONS: \", predictedLabels[10], predictedLabels[26], predictedLabels[50])\n",
    "#########################################################\n",
    "\n",
    "i = 0\n",
    "\n",
    "for prediction in predictedLabels:\n",
    "    if prediction == 1:\n",
    "        i = i + 1\n",
    "\n",
    "print(\"i = \", i)\n",
    "\n",
    "\"\"\" When kernel set to rbf and optimizing C with the following values:\n",
    "\n",
    "C = 10          Acc = 0.6160409556313993\n",
    "C = 100         Acc = 0.6160409556313993\n",
    "C = 1000        Acc = 0.8213879408418657\n",
    "C = 10000       Acc = 0.8924914675767918\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
